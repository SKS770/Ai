# 1st question 

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Load English stopwords
stop_words = set(stopwords.words("english"))

# Read input text file
with open("input.txt", "r") as file:
    text = file.read()

# Tokenize the words
words = word_tokenize(text)

# Remove stop words
filtered_words = [word for word in words if word.lower() not in stop_words]

# Convert list back to text
filtered_text = " ".join(filtered_words)

# Save to output file
with open("output.txt", "w") as file:
    file.write(filtered_text)

print("Stop words removed successfully!")
print("Cleaned text saved in output.txt")
